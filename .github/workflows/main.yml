name: Deploy to GitHub Pages

# 触发条件：当向 main 分支推送时
on:
  push:
    branches:
      - main

# 设置权限，允许写入内容
permissions:
  contents: write

jobs:
  deploy:
    name: Deploy to GitHub Pages
    runs-on: ubuntu-latest # 使用最新的 Ubuntu 环境
    steps:
      - uses: actions/checkout@v4 # 检出代码
      - uses: actions/setup-node@v4 # 设置 Node.js 环境
        with:
          node-version: 18 # 指定 Node.js 版本
          cache: yarn # 缓存 yarn 依赖

      - name: Install dependencies # 安装依赖
        run: yarn install --frozen-lockfile  --no-cache # 安装依赖并确保 lockfile 一致，不使用缓存

      - name: Build website # 构建网站
        run: |
          yarn build || echo "Build failed" # 针对 zh-CN 语言环境构建，如果失败则输出错误信息


      - name: Create CNAME file
        run: echo 'book.onlinebookshell.co.in' > ./build/CNAME

      - name: Notify Deployment
        run: |
          echo "Deployed to URL: ${{ steps.deployment.outputs.page_url }}"

      - name: Deploy to GitHub Pages # 部署到 GitHub Pages
        uses: peaceiris/actions-gh-pages@v4 # 使用 peaceiris 的 GitHub Pages 部署动作
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }} # 使用 GitHub 提供的 token
          publish_dir: ./build # 指定要发布的构建输出目录
          user_name: github-actions[bot] # 提交时使用的用户名
          user_email: 409003604@qq.com # 提交时使用的用户邮箱
          fqdn: book.onlinebookshell.co.in


  scan:
    runs-on: ubuntu-latest
    name: docsearch scraper
    steps:
      - name: Sleep for 10 seconds
        run: sleep 120s
        shell: bash

      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Run scraper
        env:
          APPLICATION_ID: ${{ secrets.APPLICATION_ID }}
          API_KEY: ${{ secrets.API_KEY }}
        run: |
          echo API_KEY: ${API_KEY}
          echo APP_ID: ${APPLICATION_ID}
          CONFIG="$(cat docsearch/docsearch-config.json)"
          docker run -i --rm \
                  -e APPLICATION_ID=$APPLICATION_ID \
                  -e API_KEY=$API_KEY \
                  -e CONFIG="${CONFIG}" \
                  algolia/docsearch-scraper
